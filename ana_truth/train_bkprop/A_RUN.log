Full training
atlas24.hep.anl.gov
Pythia8 setup
Set ROOT enviroment for Dijet+Lepton program
HOST=atlas24.hep.anl.gov 
PROMC was set to /home/chekanov/work/DoubleHiggs/SHllbb/ana_truth/lib/promc
Setup ROOT, PyROOT tensorflow
[7mlsetup              [0m lsetup <tool1> [ <tool2> ...] (see lsetup -h):
[7m lsetup asetup      [0m  (or asetup) to setup an Athena release
[7m lsetup astyle      [0m  ATLAS style macros
[7m lsetup atlantis    [0m  Atlantis: event display
[7m lsetup centralpage [0m  Find samples
[7m lsetup eiclient    [0m  Event Index 
[7m lsetup emi         [0m  EMI: grid middleware user interface 
[7m lsetup lcgenv      [0m  lcgenv: setup tools from cvmfs SFT repository
[7m lsetup panda       [0m  Panda: Production ANd Distributed Analysis
[7m lsetup pyami       [0m  pyAMI: ATLAS Metadata Interface python client
[7m lsetup root        [0m  ROOT data processing framework
[7m lsetup rucio       [0m  distributed data management system client
[7m lsetup scikit      [0m  python data analysis ecosystem
[7m lsetup views       [0m  Set up a full LCG release
[7m lsetup xcache      [0m  XRootD local proxy cache
[7m lsetup xrootd      [0m  XRootD data access
[7madvancedTools       [0m advanced tools menu
[7mdiagnostics         [0m diagnostic tools menu
[7mhelpMe              [0m more help
[7minstallPip          [0m install relocatable pip modules locally
[7minstallRpm          [0m install relocatable rpms locally
[7mprintMenu           [0m show this menu
[7mqueryC              [0m find / whatis container query
[7mshowVersions        [0m show versions of installed software


[1m[4m30 Nov 2023[0m 

A serious security issue in ROOT's web-based GUI has been identified:

  You should not use the web-based browser until further notice and instead 
  set the old-style TBrowser as the default. Please see the Twiki page linked 
  below for instructions on how to do this.

  https://twiki.cern.ch/twiki/bin/view/AtlasComputing/AtlasComputingArchive/RootBrowserSecurityIssue

  More details of this issue:
  https://root.cern/about/security/#2023-11-26-open-port-for-control-of-web-gui-allows-read-and-write-access-to-file-system

  [0;31mReason for this message: $HOME/.rootrc is missing[0m 

************************************************************************
Requested:  views ... 
 Setting up [4mviews LCG_105:x86_64-el9-gcc13-opt[0m ... 
>>>>>>>>>>>>>>>>>>>>>>>>> Information for user <<<<<<<<<<<<<<<<<<<<<<<<<
************************************************************************
Setup Fastjet
Read= out/pythia8_X500GeV_HH2bbll_data100percent.csv.gz
Found mass= 500.0
Nr of columns= 1295
Nr of columns after adding mass= 1296
Input= out/pythia8_X500GeV_HH2bbll_data100percent.csv.gz  DF size= 36133776  DF shape= (27881, 1296)  DF dimension= 2
Read= out/pythia8_X700GeV_HH2bbll_data100percent.csv.gz
Found mass= 700.0
Nr of columns= 1295
Nr of columns after adding mass= 1296
Input= out/pythia8_X700GeV_HH2bbll_data100percent.csv.gz  DF size= 34792416  DF shape= (26846, 1296)  DF dimension= 2
Read= out/pythia8_X1000GeV_HH2bbll_data100percent.csv.gz
Found mass= 1000.0
Nr of columns= 1295
Nr of columns after adding mass= 1296
Input= out/pythia8_X1000GeV_HH2bbll_data100percent.csv.gz  DF size= 30980880  DF shape= (23905, 1296)  DF dimension= 2
Read= out/pythia8_X1500GeV_HH2bbll_data100percent.csv.gz
Found mass= 1500.0
Nr of columns= 1295
Nr of columns after adding mass= 1296
Input= out/pythia8_X1500GeV_HH2bbll_data100percent.csv.gz  DF size= 21218112  DF shape= (16372, 1296)  DF dimension= 2
Read= out/pythia8_X2000GeV_HH2bbll_data100percent.csv.gz
Found mass= 2000.0
Nr of columns= 1295
Nr of columns after adding mass= 1296
Input= out/pythia8_X2000GeV_HH2bbll_data100percent.csv.gz  DF size= 14113440  DF shape= (10890, 1296)  DF dimension= 2
Final after append: size= 137238624  DF shape= (105894, 1296)  DF dimension= 2
Read= out/tev13.6pp_pythia8_ttbar_2lep_data10percent.csv.gz
Nr of columns= 1295
Nr of columns after adding mass= 1296
Input= out/tev13.6pp_pythia8_ttbar_2lep_data10percent.csv.gz  DF size= 257196384  DF shape= (198454, 1296)  DF dimension= 2
After trim SM to signal size= DF size= 137238624  DF shape= (105894, 1296)  DF dimension= 2
Train on 10% of data, as for the AD filter
## Data Preprocessing:
-> Validation fraction= 0.9  Training fraction= 0.09999999999999998
Training data size   : (10589, 1296)
Validation data size : (95305, 1296)
Size of outputs= 10589
BSM Training data size   : (10589, 1296)
BSM Validation data size : (95305, 1296)
SM Training data size   : (10589, 1296)
SM Validation data size : (95305, 1296)
Training data size after append  : (21178, 1296)
Validation data size after append : (190610, 1296)
input_dim : 1296
Max epochs for = 200
Epoch 1/200
2118/2118 - 7s - loss: 0.2175 - accuracy: 0.9128 - 7s/epoch - 3ms/step
Epoch 2/200
2118/2118 - 6s - loss: 0.1405 - accuracy: 0.9468 - 6s/epoch - 3ms/step
Epoch 3/200
2118/2118 - 5s - loss: 0.1231 - accuracy: 0.9537 - 5s/epoch - 3ms/step
Epoch 4/200
2118/2118 - 6s - loss: 0.1135 - accuracy: 0.9565 - 6s/epoch - 3ms/step
Epoch 5/200
2118/2118 - 7s - loss: 0.1015 - accuracy: 0.9626 - 7s/epoch - 3ms/step
Epoch 6/200
2118/2118 - 7s - loss: 0.0957 - accuracy: 0.9630 - 7s/epoch - 3ms/step
Epoch 7/200
2118/2118 - 7s - loss: 0.0893 - accuracy: 0.9663 - 7s/epoch - 3ms/step
Epoch 8/200
2118/2118 - 7s - loss: 0.0844 - accuracy: 0.9687 - 7s/epoch - 3ms/step
Epoch 9/200
2118/2118 - 7s - loss: 0.0799 - accuracy: 0.9703 - 7s/epoch - 3ms/step
Epoch 10/200
2118/2118 - 7s - loss: 0.0774 - accuracy: 0.9725 - 7s/epoch - 3ms/step
Epoch 11/200
2118/2118 - 7s - loss: 0.0724 - accuracy: 0.9722 - 7s/epoch - 3ms/step
Epoch 12/200
2118/2118 - 7s - loss: 0.0690 - accuracy: 0.9735 - 7s/epoch - 3ms/step
Epoch 13/200
2118/2118 - 7s - loss: 0.0658 - accuracy: 0.9757 - 7s/epoch - 3ms/step
Epoch 14/200
2118/2118 - 7s - loss: 0.0642 - accuracy: 0.9768 - 7s/epoch - 3ms/step
Epoch 15/200
2118/2118 - 7s - loss: 0.0592 - accuracy: 0.9779 - 7s/epoch - 3ms/step
Epoch 16/200
2118/2118 - 7s - loss: 0.0581 - accuracy: 0.9786 - 7s/epoch - 3ms/step
Epoch 17/200
2118/2118 - 7s - loss: 0.0543 - accuracy: 0.9797 - 7s/epoch - 3ms/step
Epoch 18/200
2118/2118 - 7s - loss: 0.0515 - accuracy: 0.9807 - 7s/epoch - 3ms/step
Epoch 19/200
2118/2118 - 7s - loss: 0.0483 - accuracy: 0.9815 - 7s/epoch - 3ms/step
Epoch 20/200
2118/2118 - 7s - loss: 0.0469 - accuracy: 0.9833 - 7s/epoch - 3ms/step
Epoch 21/200
2118/2118 - 7s - loss: 0.0453 - accuracy: 0.9836 - 7s/epoch - 3ms/step
Epoch 22/200
2118/2118 - 7s - loss: 0.0419 - accuracy: 0.9842 - 7s/epoch - 3ms/step
Epoch 23/200
2118/2118 - 7s - loss: 0.0448 - accuracy: 0.9834 - 7s/epoch - 3ms/step
Epoch 24/200
2118/2118 - 7s - loss: 0.0391 - accuracy: 0.9845 - 7s/epoch - 3ms/step
Epoch 25/200
2118/2118 - 7s - loss: 0.0365 - accuracy: 0.9860 - 7s/epoch - 3ms/step
Epoch 26/200
2118/2118 - 7s - loss: 0.0347 - accuracy: 0.9866 - 7s/epoch - 3ms/step
Epoch 27/200
2118/2118 - 7s - loss: 0.0370 - accuracy: 0.9865 - 7s/epoch - 3ms/step
Epoch 28/200
2118/2118 - 7s - loss: 0.0320 - accuracy: 0.9872 - 7s/epoch - 3ms/step
Epoch 29/200
2118/2118 - 7s - loss: 0.0330 - accuracy: 0.9879 - 7s/epoch - 3ms/step
Epoch 30/200
2118/2118 - 7s - loss: 0.0289 - accuracy: 0.9892 - 7s/epoch - 3ms/step
Epoch 31/200
2118/2118 - 7s - loss: 0.0300 - accuracy: 0.9884 - 7s/epoch - 3ms/step
Epoch 32/200
2118/2118 - 7s - loss: 0.0307 - accuracy: 0.9892 - 7s/epoch - 3ms/step
Epoch 33/200
2118/2118 - 7s - loss: 0.0241 - accuracy: 0.9909 - 7s/epoch - 3ms/step
Epoch 34/200
2118/2118 - 7s - loss: 0.0269 - accuracy: 0.9902 - 7s/epoch - 3ms/step
Epoch 35/200
2118/2118 - 7s - loss: 0.0260 - accuracy: 0.9903 - 7s/epoch - 3ms/step
Epoch 36/200
2118/2118 - 7s - loss: 0.0249 - accuracy: 0.9913 - 7s/epoch - 3ms/step
Epoch 37/200
2118/2118 - 7s - loss: 0.0255 - accuracy: 0.9907 - 7s/epoch - 3ms/step
Epoch 38/200
2118/2118 - 7s - loss: 0.0227 - accuracy: 0.9914 - 7s/epoch - 3ms/step
Epoch 39/200
2118/2118 - 7s - loss: 0.0206 - accuracy: 0.9925 - 7s/epoch - 3ms/step
Epoch 40/200
2118/2118 - 7s - loss: 0.0195 - accuracy: 0.9930 - 7s/epoch - 3ms/step
Epoch 41/200
2118/2118 - 7s - loss: 0.0204 - accuracy: 0.9924 - 7s/epoch - 3ms/step
Epoch 42/200
2118/2118 - 7s - loss: 0.0210 - accuracy: 0.9924 - 7s/epoch - 3ms/step
Epoch 43/200
2118/2118 - 7s - loss: 0.0201 - accuracy: 0.9923 - 7s/epoch - 3ms/step
Epoch 44/200
2118/2118 - 7s - loss: 0.0203 - accuracy: 0.9925 - 7s/epoch - 3ms/step
Epoch 45/200
2118/2118 - 7s - loss: 0.0183 - accuracy: 0.9941 - 7s/epoch - 3ms/step
Epoch 46/200
2118/2118 - 7s - loss: 0.0194 - accuracy: 0.9927 - 7s/epoch - 3ms/step
Epoch 47/200
2118/2118 - 7s - loss: 0.0173 - accuracy: 0.9937 - 7s/epoch - 3ms/step
Epoch 48/200
2118/2118 - 7s - loss: 0.0144 - accuracy: 0.9947 - 7s/epoch - 3ms/step
Epoch 49/200
2118/2118 - 7s - loss: 0.0215 - accuracy: 0.9928 - 7s/epoch - 3ms/step
Epoch 50/200
2118/2118 - 7s - loss: 0.0129 - accuracy: 0.9950 - 7s/epoch - 3ms/step
Epoch 51/200
2118/2118 - 7s - loss: 0.0167 - accuracy: 0.9934 - 7s/epoch - 3ms/step
Epoch 52/200
2118/2118 - 7s - loss: 0.0131 - accuracy: 0.9952 - 7s/epoch - 3ms/step
Epoch 53/200
2118/2118 - 7s - loss: 0.0123 - accuracy: 0.9954 - 7s/epoch - 3ms/step
Epoch 54/200
2118/2118 - 7s - loss: 0.0199 - accuracy: 0.9931 - 7s/epoch - 3ms/step
Epoch 55/200
2118/2118 - 7s - loss: 0.0129 - accuracy: 0.9954 - 7s/epoch - 3ms/step
Epoch 56/200
2118/2118 - 7s - loss: 0.0148 - accuracy: 0.9949 - 7s/epoch - 3ms/step
Epoch 57/200
2118/2118 - 7s - loss: 0.0130 - accuracy: 0.9959 - 7s/epoch - 3ms/step
Epoch 58/200
2118/2118 - 7s - loss: 0.0113 - accuracy: 0.9958 - 7s/epoch - 3ms/step
Epoch 59/200
2118/2118 - 7s - loss: 0.0165 - accuracy: 0.9942 - 7s/epoch - 3ms/step
Epoch 60/200
2118/2118 - 7s - loss: 0.0133 - accuracy: 0.9959 - 7s/epoch - 3ms/step
Epoch 61/200
2118/2118 - 7s - loss: 0.0104 - accuracy: 0.9962 - 7s/epoch - 3ms/step
Epoch 62/200
2118/2118 - 7s - loss: 0.0097 - accuracy: 0.9968 - 7s/epoch - 3ms/step
Epoch 63/200
2118/2118 - 7s - loss: 0.0129 - accuracy: 0.9956 - 7s/epoch - 3ms/step
Epoch 64/200
2118/2118 - 7s - loss: 0.0108 - accuracy: 0.9963 - 7s/epoch - 3ms/step
Epoch 65/200
2118/2118 - 7s - loss: 0.0174 - accuracy: 0.9952 - 7s/epoch - 3ms/step
Epoch 66/200
2118/2118 - 7s - loss: 0.0076 - accuracy: 0.9970 - 7s/epoch - 3ms/step
Epoch 67/200
2118/2118 - 7s - loss: 0.0150 - accuracy: 0.9953 - 7s/epoch - 3ms/step
Epoch 68/200
2118/2118 - 7s - loss: 0.0105 - accuracy: 0.9964 - 7s/epoch - 3ms/step
Epoch 69/200
2118/2118 - 7s - loss: 0.0102 - accuracy: 0.9964 - 7s/epoch - 3ms/step
Epoch 70/200
2118/2118 - 7s - loss: 0.0115 - accuracy: 0.9962 - 7s/epoch - 3ms/step
Epoch 71/200
2118/2118 - 7s - loss: 0.0125 - accuracy: 0.9957 - 7s/epoch - 3ms/step
accuracy: 99.67%
Saved model to disk: models/model.h5
Loaded model from disk
accuracy: 95.65%
